{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text mining and analyses using nursery rhymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rochiecuevas/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rochiecuevas/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rochiecuevas/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "# Dependencies for creating the dataframe and for preliminary data analyses\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import re, string\n",
    "from time import time\n",
    "from IPython.core.display import clear_output\n",
    "\n",
    "# Dependencies for natural language processing\n",
    "import nltk\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data from the database into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the database table into a dataframe\n",
    "conn = sqlite3.connect(\"db/nursery_rhymes.sqlite\") # connect to the database\n",
    "df = pd.read_sql_query(\"SELECT * FROM Nursery_Rhymes;\", conn) # get the contents of the Nursery_Rhymes table\n",
    "conn.close() # close the connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Title</th>\n",
       "      <th>URLs</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A Sailor Went To Sea</td>\n",
       "      <td>a-sailor-went-to-sea.html</td>\n",
       "      <td>A sailor went to sea, sea, sea \\n        To se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A-Tisket, A-Tasket</td>\n",
       "      <td>a-tisket-a-tasket.html</td>\n",
       "      <td>A-tisket, a-tasket\\nA green and yellow basket\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A Wise Old Owl</td>\n",
       "      <td>a-wise-old-owl.html</td>\n",
       "      <td>A wise old owl lived in an oak.\\nThe more he s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A, You're Adorable</td>\n",
       "      <td>a-you-re-adorable.html</td>\n",
       "      <td>\"A\" you're adorable\\n      \"B\" you're so beaut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ABC Song</td>\n",
       "      <td>abc-song.html</td>\n",
       "      <td>A for Apple, A for Ant\\nB for Ball, B for Bat\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                 Title                       URLs  \\\n",
       "0      0  A Sailor Went To Sea  a-sailor-went-to-sea.html   \n",
       "1      1    A-Tisket, A-Tasket     a-tisket-a-tasket.html   \n",
       "2      2        A Wise Old Owl        a-wise-old-owl.html   \n",
       "3      3    A, You're Adorable     a-you-re-adorable.html   \n",
       "4      4              ABC Song              abc-song.html   \n",
       "\n",
       "                                              Lyrics  \n",
       "0  A sailor went to sea, sea, sea \\n        To se...  \n",
       "1  A-tisket, a-tasket\\nA green and yellow basket\\...  \n",
       "2  A wise old owl lived in an oak.\\nThe more he s...  \n",
       "3  \"A\" you're adorable\\n      \"B\" you're so beaut...  \n",
       "4  A for Apple, A for Ant\\nB for Ball, B for Bat\\...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning: Tokenise, remove stop words, lemmatise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from the list\n",
    "stops = stopwords.words(\"english\")\n",
    "exclude = list(set(string.punctuation))\n",
    "\n",
    "# Lemmatise the words in each list to retain their roots\n",
    "lemmatiser = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'sailor',\n",
       " 'went',\n",
       " 'to',\n",
       " 'sea',\n",
       " ',',\n",
       " 'sea',\n",
       " ',',\n",
       " 'sea',\n",
       " 'To',\n",
       " 'see',\n",
       " 'what',\n",
       " 'he',\n",
       " 'could',\n",
       " 'see',\n",
       " ',',\n",
       " 'see',\n",
       " ',',\n",
       " 'see',\n",
       " 'But',\n",
       " 'all',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'see',\n",
       " ',',\n",
       " 'see',\n",
       " ',',\n",
       " 'see',\n",
       " 'Was',\n",
       " 'the',\n",
       " 'bottom',\n",
       " 'of',\n",
       " 'the',\n",
       " 'deep',\n",
       " 'blue',\n",
       " 'sea',\n",
       " ',',\n",
       " 'sea',\n",
       " ',',\n",
       " 'sea',\n",
       " '!',\n",
       " 'A',\n",
       " 'sailor',\n",
       " 'went',\n",
       " 'to',\n",
       " 'knee',\n",
       " ',',\n",
       " 'knee',\n",
       " ',',\n",
       " 'knee',\n",
       " 'To',\n",
       " 'see',\n",
       " 'what',\n",
       " 'he',\n",
       " 'could',\n",
       " 'knee',\n",
       " ',',\n",
       " 'knee',\n",
       " ',',\n",
       " 'knee',\n",
       " 'But',\n",
       " 'all',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'knee',\n",
       " ',',\n",
       " 'knee',\n",
       " ',',\n",
       " 'knee',\n",
       " 'Was',\n",
       " 'the',\n",
       " 'bottom',\n",
       " 'of',\n",
       " 'the',\n",
       " 'deep',\n",
       " 'blue',\n",
       " 'knee',\n",
       " ',',\n",
       " 'knee',\n",
       " ',',\n",
       " 'knee',\n",
       " '!',\n",
       " '(',\n",
       " 'Sea',\n",
       " ',',\n",
       " 'sea',\n",
       " ',',\n",
       " 'sea',\n",
       " ')',\n",
       " 'A',\n",
       " 'sailor',\n",
       " 'went',\n",
       " 'to',\n",
       " 'chop',\n",
       " ',',\n",
       " 'chop',\n",
       " ',',\n",
       " 'chop',\n",
       " 'To',\n",
       " 'see',\n",
       " 'what',\n",
       " 'he',\n",
       " 'could',\n",
       " 'chop',\n",
       " ',',\n",
       " 'chop',\n",
       " ',',\n",
       " 'chop',\n",
       " 'But',\n",
       " 'all',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'chop',\n",
       " ',',\n",
       " 'chop',\n",
       " ',',\n",
       " 'chop',\n",
       " 'Was',\n",
       " 'the',\n",
       " 'bottom',\n",
       " 'of',\n",
       " 'the',\n",
       " 'deep',\n",
       " 'blue',\n",
       " 'chop',\n",
       " ',',\n",
       " 'chop',\n",
       " ',',\n",
       " 'chop',\n",
       " '!',\n",
       " '(',\n",
       " 'Sea',\n",
       " ',',\n",
       " 'sea',\n",
       " ',',\n",
       " 'sea',\n",
       " ')',\n",
       " '(',\n",
       " 'Knee',\n",
       " ',',\n",
       " 'knee',\n",
       " ',',\n",
       " 'knee',\n",
       " ')']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = word_tokenize(df[\"Lyrics\"][0])\n",
    "words1 = [word for word in words if word not in stops or word not in exclude]\n",
    "words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
